import seaborn as sns
import pandas as pd
import numpy as np
import cv2
import os, random, shutil, glob
import matplotlib.pyplot as plt
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Flatten, Dense, Conv2D, Activation, Dropout, MaxPooling2D, GlobalAveragePooling2D
from tensorflow.keras.optimizers import SGD, Adam, RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.applications import VGG16, Xception
import tensorflow as tf
from keras import optimizers

import tensorflow_datasets as tfds
from keras.constraints import maxnorm
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import time

# import from other scripts in Labb folder
from plot_images import display_images_encoded, count_plot, joint_plot, check_if_random_plot
from file_handling import create_directory

os.chdir(os.path.dirname(__file__))

current_dir = os.path.abspath("")
print(f"{current_dir=}")

# list all files in current dir
files_current_dir = os.listdir(current_dir)
print(f"{files_current_dir=}")

original_data_train_dir = os.path.abspath("original_data/train/train")
original_data_test_dir = os.path.abspath("original_data/test/test")

files_current_dir = os.listdir(original_data_train_dir)

ten_train_images = random.sample(os.listdir(original_data_train_dir), k=10)
ten_test_images = random.sample(os.listdir(original_data_test_dir), k=10)
#print(ten_train_images)
#print(ten_test_images)
"""
print output till rapporten
output1:
['cat.3252.jpg', 'dog.8633.jpg', 'dog.12190.jpg', 'cat.536.jpg', 'cat.9290.jpg', 'cat.10800.jpg', 'dog.886.jpg', 'dog.2112.jpg', 'cat.11950.jpg', 'dog.10157.jpg']
['546.jpg', '3132.jpg', '5115.jpg', '9069.jpg', '11672.jpg', '7093.jpg', '8392.jpg', '7731.jpg', '4017.jpg', '1005.jpg']

output2:
['cat.10195.jpg', 'dog.10587.jpg', 'dog.9408.jpg', 'dog.7288.jpg', 'cat.10062.jpg', 'cat.11976.jpg', 'cat.8836.jpg', 'cat.4314.jpg', 'dog.10579.jpg', 'dog.9582.jpg']
['4332.jpg', '31.jpg', '3340.jpg', '11770.jpg', '6027.jpg', '7801.jpg', '8964.jpg', '3425.jpg', '11683.jpg', '10927.jpg']
"""
# 10 plots from Original Train and Original Test
"""
display_images_encoded(ten_train_images, title="10 Original Train images", get_labels=False, path=original_data_train_dir)
display_images_encoded(ten_test_images, title="10 Original Test images", get_labels=False, path=original_data_test_dir)
"""

create_directory(current_dir)

"""
d) Nu ska du göra train|val|test split med följande splits:
experiment_small
"""
# random.sample - Used for random sampling without replacement.
# random.seed - Initialize the random number generator. Seed function is used to save the state of a random function,
# so that it can generate same random numbers on multiple executions of the code on the same machine or on different
# machines (for a specific seed value). The seed value is the previous value number generated by the generator.
# For the first time when there is no previous value, it uses current system time.
random.seed(142)  # 42
image_small_data = random.sample(os.listdir(original_data_train_dir), k=5000)

# sort in cats and dogs for saving to path according to amount
cats = [image for image in image_small_data if image[:3] == 'cat']
dogs = [image for image in image_small_data if image[:3] == 'dog']


# {}, kollade nu left shift + right option + 8/9

def save_data_to_folder(image_lst):
    train_lst = []
    val_lst = []
    test_lst = []

    for data in image_lst:
        train_lst.extend(data[:800])
        val_lst.extend(data[800:1000])
        test_lst.extend(data[1000:1250])

    def copy_to_folder(file_lst, folder):
        if len(os.listdir(folder)) != 0:
            files = glob.glob(folder+'/*.jpg')
            for f in files:
                try:
                    os.remove(f)
                except OSError as e:
                    print("Error: %s : %s" % (f, e.strerror))
                continue
        if len(os.listdir(folder)) == 0:
            for filename in file_lst:
                src = f"{original_data_train_dir}/{filename}"
                dst = f"{folder}/{filename}"
                shutil.copyfile(src, dst)

    # testa om utan inre def, så som jag testade innan
    copy_to_folder(train_lst, f'{current_dir}/experiment_small_data/train/')
    copy_to_folder(val_lst, f'{current_dir}/experiment_small_data/val/')
    copy_to_folder(test_lst, f'{current_dir}/experiment_small_data/test/')


save_data_to_folder([cats, dogs])


# för att dubbelkolla ovasntående funktion
lenght_train = len(os.listdir(f'{current_dir}/experiment_small_data/train/'))
lenght_test = len(os.listdir(f'{current_dir}/experiment_small_data/test/'))
lenght_val = len(os.listdir(f'{current_dir}/experiment_small_data/val/'))
print(lenght_train, lenght_test, lenght_val)

"""
e) Läs in dataseten från experiment_small, experiment_tiny och plocka ut labelsvektorer, som ska vara
one-hot encoded med 0 och 1.
plotta några bilder med deras respektive labels och kontrollera att det är korrekt.
skapa lämplig plot för att kontrollera att dataseten är balanserade
skapa lämplig plot för att kontrollera att dataseten är slumpade (dvs inte ex [0, 0, ... 0, 1, 1, ..., 1]). KVAR gör lineplot per test, train, val och hela datan (5000)
"""
# ska dessa vara kvar - kolla igenom noga innan släng
train_path = os.path.abspath("experiment_small_data/train")
test_path = os.path.abspath("experiment_small_data/test")
val_path = os.path.abspath("experiment_small_data/val")


def label_or_one_hot_encode(img_path, get_encoded=False):
    ''' fick inspo av Daniel och Felix, jag hade lagt två fkn som gjorde respektive
    och i förra labben tappade jag en så det blev fel så jag ville få in dem så jag inte tappade
    dom som sker om manuellt inlagt'''
    if img_path.split(".")[0][-3:] == 'cat':
        if get_encoded:
            return 1
        """
        t = img_path.split(".")[0][-3:]
        tt = img_path.split(".")[0]
        ttt = img_path.split(".")"""
        return 'cat'
    else:
        if get_encoded:
            return 0
        return 'dog'


# glob finds all the path names matching a specified pattern according to the rules used by the Unix shell
train_image = [(plt.imread(img_path), label_or_one_hot_encode(img_path)) for img_path in
               glob.glob(f'{current_dir}/experiment_small_data/train/*.jpg')]
test_image = [(plt.imread(img_path), label_or_one_hot_encode(img_path)) for img_path in
              glob.glob(f'{current_dir}/experiment_small_data/test/*.jpg')]
val_image = [(plt.imread(img_path), label_or_one_hot_encode(img_path)) for img_path in
             glob.glob(f'{current_dir}/experiment_small_data/val/*.jpg')]

random.shuffle(train_image)
random.shuffle(test_image)
random.shuffle(val_image)

# bra sida att kolla på
# https://studymachinelearning.com/keras-imagedatagenerator-with-flow/
# one hot encode exempel, valde dock att lägga in det i en funktion som anropas i div funktioner
# daniels
# labels = image_small_data
# labels = np.array([1 if label[:3] == 'cat' else 0 for label in labels])

"""display_images_encoded(val_image[:10], title="10 Val images - small data", path=False, get_labels=True)
display_images_encoded(test_image[:10], title="10 Test images - small data", path=False, get_labels=True)
display_images_encoded(train_image[:10], title="10 Train images - small data", path=False, get_labels=True)"""


# used for plot to check random order and count plot
val_encoded = [label_or_one_hot_encode(img[1], get_encoded=True) for img in val_image]
train_encoded = [label_or_one_hot_encode(img[1], get_encoded=True) for img in train_image]
test_encoded = [label_or_one_hot_encode(img[1], get_encoded=True) for img in test_image]

"""check_if_random_plot((train_encoded, test_encoded, val_encoded),
                     ("Train random plot", "Test random plot", "Validation random plot"))

count_plot(val_encoded, "Val_images")
count_plot(train_encoded, "Train_images")
count_plot(test_encoded, "Test_images")"""


train_image = [(plt.imread(img_path), label_or_one_hot_encode(img_path)) for img_path in
               glob.glob(f'{current_dir}/experiment_small_data/train/*.jpg')]

test_image = [(plt.imread(img_path), label_or_one_hot_encode(img_path)) for img_path in
              glob.glob(f'{current_dir}/experiment_small_data/test/*.jpg')]

val_image = [(plt.imread(img_path), label_or_one_hot_encode(img_path)) for img_path in
             glob.glob(f'{current_dir}/experiment_small_data/val/*.jpg')]


def get_size_of_images(img_lst):
    return [img[0].shape for img in img_lst]


img_sizes = pd.DataFrame(get_size_of_images(train_image) + get_size_of_images(test_image) +
                         get_size_of_images(val_image), columns=["height", "width", "color"])

print("Min:", img_sizes.min(), "\nMax:", img_sizes.max())
""" In to rapport:
Min: height 37.0    width 3.0     color 3.0
Max: height 500.0   width 500.0   color 3.0
"""

# joint_plot(img_sizes)

""" många som ligger 500x500 några få under 100x100, det ligger en ansamling vid 200x200, de flesta är över 160x160
bilder under 160x160 eller 200x200 bör slängas tror jag resized_val_images = [(cv2.resize(image[0], (100, 100)), image[1]) for image in data]
"""


def preprocessing_data(data):
    # resized_shape = [data_resized[i].shape for i in range(len(data_resized))]
    resized_val_images = [(cv2.resize(img[0], (160, 160)), img[1]) for img in data]
    # testar 300, 300, bytte 160x160 pga tid
    return resized_val_images


train_resized = preprocessing_data(train_image)
test_resized = preprocessing_data(test_image)
val_resized = preprocessing_data(val_image)

"""random.shuffle(train_resized)
random.shuffle(test_resized)
random.shuffle(val_resized)"""

"""display_images_encoded(train_resized[:10], title="Train resized - small data", get_labels=True, path=False)
display_images_encoded(test_resized[:10], title="Test resized - small data", get_labels=True, path=False)
display_images_encoded(val_resized[:10], title="Val resized - small data", get_labels=True, path=False)"""

# Train|val|test split and Normalize data
print()
scaled_X_train = np.array([image[0] for image in train_resized]).astype("float32") / 255.0 + 0.01
scaled_X_test = np.array([image[0] for image in test_resized]).astype("float32") / 255.0 + 0.01
scaled_X_val = np.array([image[0] for image in val_resized]).astype("float32") / 255.0 + 0.01
print("scaled_X", scaled_X_train.shape, scaled_X_test.shape, scaled_X_val.shape)
"""scaled_X_train3 = np.array([image[0] for image in train_resized]).astype("float32") / 255.0 
print(scaled_X_train3[0].min(), scaled_X_train3[1].min(), scaled_X_train3[2].min())
print(scaled_X_val[0].min(), scaled_X_val[1].min(), scaled_X_val[2].min())
print(scaled_X_test[0].min(), scaled_X_test[0].min(), scaled_X_test[0].min())"""
# adding 0.01 to the result. This way, we avoid 0 values as inputs, which are capable of preventing weight updates
# https://python-course.eu/machine-learning/training-and-testing-with-mnist.php

# Train|val|test split
y_train = np.array([label_or_one_hot_encode(image[1], get_encoded=True) for image in train_resized])
y_test = np.array([label_or_one_hot_encode(image[1], get_encoded=True) for image in test_resized])
y_val = np.array([label_or_one_hot_encode(image[1], get_encoded=True) for image in val_resized])
print("scaled_y and encoded_y", y_train.shape, y_test.shape, y_val.shape)

# concatenate of Train+val
scaled_X_train_val = np.concatenate((scaled_X_train, scaled_X_val), axis=0)
y_train_val = np.concatenate((y_train, y_val), axis=0)
print("scaled_X_train_val and y_train_val", scaled_X_train_val.shape, y_train_val.shape)


# Evaluation
def evaluation(model, x_for_pred, y_param, title):
    y_pred = model.predict(x_for_pred)
    y_pred = (y_pred > .5) * 1
    """
    y_pred_small_aug > .5 evalueras till True, dvs 1 om sigmoidfunktionen ger 
    svaret att sannolikheten att det är en etta är större än att det är en nolla, det vill säga ett värde över 0.5
    Och om det är lägre än 0.5 så blir det då False
    Gissar att vi multiplicerar med 1 för att få det till ett faktiskt värde och inte True eller False
    """
    print("Evaluation:", title)
    print(classification_report(y_param, y_pred))

    cm = confusion_matrix(y_param, y_pred)
    ConfusionMatrixDisplay(cm).plot()
    plt.savefig('saved_images/'+ f"confusion_matrix__{title}.png")
    # plt.show()

    """
    y_pred_misclassified = model.predict(x_for_pred)
    y_pred_misclassified = (y_pred > .5)*1
    misclassified_indices = np.where(y_pred_misclassified != y_param)[0]
    misclassified_samples = scaled_X_val[misclassified_indices]
    print("number of misclassified images:", (misclassified_samples.shape))

    # a few misclassifications
    random.shuffle(misclassified_samples)
    display_images_encoded(misclassified_samples, title="Misclassified", nrows=10, ncols=6, path=False, get_labels=False)
    """


def plot_metrics(metrics, title):
    _, ax = plt.subplots(1, 2, figsize=(12, 4))
    metrics[["loss", "val_loss"]].plot(ax=ax[0], title=title, grid=True)
    metrics[["acc", "val_acc"]].plot(ax=ax[1], title=title, grid=True)
    plt.savefig(f"saved_images/metrics__{title}.png")
    # plt.show()


"""
Data augmentation
"""
# testa olika inställningar i taget!
augmented_image_generator = ImageDataGenerator(rotation_range=10, shear_range=.2, zoom_range=.1, horizontal_flip=1,
                                               height_shift_range=.2, width_shift_range=.2, vertical_flip=0)

wo_augmented_image_generator = ImageDataGenerator()  # for no augmentation

augmented_train_generator = augmented_image_generator.flow(scaled_X_train, y_train, batch_size=32)

wo_augumented_train_generator = wo_augmented_image_generator.flow(scaled_X_train, y_train, batch_size=32)

val_generator = wo_augmented_image_generator.flow(scaled_X_val, y_val, batch_size=32)

test_generator = wo_augmented_image_generator.flow(scaled_X_test, y_test, batch_size=32)
# här ska hela train+val in på flow och in fit
train_val_generator = augmented_image_generator.flow(scaled_X_train_val, y_train_val, batch_size=32)
train_val_wo_generator = wo_augmented_image_generator.flow(scaled_X_train_val, y_train_val, batch_size=32)

print(len(augmented_train_generator.next()))
sample_batch = augmented_train_generator.next()
print("sample_batch", len(sample_batch))
print("sample_batch[0]", sample_batch[0].shape)

# display_images_encoded(sample_batch[0], title="augumented", path=False, get_labels=False)


# CNN model
def CNN_model(kernels, drop_rate, learn_rate, to_input_shape):
    model = Sequential(name="CNN_model")

    # the convolutional layers
    for number_kernel in kernels:
        conv_layer = Conv2D(number_kernel,
                            kernel_size=(3, 3),
                            activation="relu",
                            kernel_initializer="he_normal",
                            input_shape=to_input_shape.shape[1:])
        # scaled_X_train kört med det i alla tuningar sen blev det fel iom train_val men då var tuningen klar
        model.add(conv_layer)
        model.add(MaxPooling2D(pool_size=(2, 2), strides=2))

    # MLP layers
    model.add(Flatten())
    model.add(Dropout(drop_rate))
    model.add(Dense(512, activation="relu", kernel_initializer="he_normal"))
    model.add(Dense(1, activation="sigmoid"))

    model.compile(loss="binary_crossentropy", optimizer=Adam(learning_rate=learn_rate), metrics=["acc"])
    # binary crossentropy since binary

    return model


model = CNN_model(kernels=[32, 64, 128, 128], drop_rate=.3, learn_rate=.001, to_input_shape=scaled_X_train)
model.summary()

# Train on augmented data
steps_per_epoch = int(len(scaled_X_train) / 32)
validation_steps = int(len(scaled_X_val) / 32)

# print(steps_per_epoch, validation_steps)
"""early_stopper = EarlyStopping(monitor="val_acc", mode="max", patience=15, restore_best_weights=True)

model.fit(augmented_train_generator, steps_per_epoch=steps_per_epoch, epochs=100, callbacks=[early_stopper],
          validation_data=val_generator, validation_steps=validation_steps)

metrics = pd.DataFrame(model.history.history)
plot_metrics(metrics, "Augmented Training X_train")
evaluation(model, scaled_X_val, y_val, "Augmented_Training_train_val")

"""
# Train wo augmented data

# denna är den jag valt
"""early_stopper = EarlyStopping(monitor="val_acc", mode="max", patience=15, restore_best_weights=True)  # True

model.fit(wo_augumented_train_generator, steps_per_epoch=steps_per_epoch, epochs=100, callbacks=[early_stopper],
          validation_data=val_generator, validation_steps=validation_steps)

metrics_wo = pd.DataFrame(model.history.history)
plot_metrics(metrics_wo, "wo_augmented_Training")
evaluation(model, scaled_X_val, y_val, "wo_augmented_Training_train_val")
"""
# Train on both train+val augmented data
# slå ihop train och val -> scaled_X_train_val scaled_X_train_val, y_train_val - gjort längre upp
# train + val ska in för fit, evaluation på test och en generator för augmentering
# så även val får augmenterade bilder

model_all = CNN_model(kernels=[32, 64, 128, 128], drop_rate=.3, learn_rate=.001, to_input_shape=scaled_X_train_val)
model_all.summary()

"""model_all.fit(train_val_generator, steps_per_epoch=steps_per_epoch, epochs=10)  # nyss 30 verkar ändra sig hela tiden suck
#epochs väljs på loss kurvorna där overfitting startar och undvika dataleakage så testdata är inte är valdigeringsdata
model_all.save('saved_models/train_val_generator.h5')

evaluation(model_all, scaled_X_test, y_test, "Augmented_Training_train_+_val__test")"""
# Train on augmented data
steps_per_epoch_all = int(len(scaled_X_train_val) / 32)
validation_steps_all = int(len(scaled_X_test) / 32)
print(steps_per_epoch_all, validation_steps_all)

"""# Train on both train+val wo augmented data
model_all.fit(train_val_wo_generator, steps_per_epoch=steps_per_epoch_all, epochs=10) # nyss 30 verkar ändra sig hela tiden suck
#epochs väljs på loss kurvorna där overfitting startar och undvika dataleakage så testdata är inte är valdigeringsdata
model_all.save('saved_models/train_val_wo_generator.h5')
evaluation(model_all, scaled_X_test, y_test, "Wo_augmented_Training_train_+_val__test")"""

# Transfer learning # kolla mer på Lec_6
# prefetch always get one batch of data ready
# GPu work on backpropagation and forward propagation while CPU works on preprocessing a batch
# buffer size ska vara mindre än totala antalet i datasetet - se mer på tensorflow
"""
använde inte, funkade ännu sämmre än nuvarande
train_dataset = tf.data.Dataset.from_tensor_slices((scaled_X_train, y_train)).shuffle(buffer_size=600) \
    .batch(32).prefetch(1)
test_dataset = tf.data.Dataset.from_tensor_slices((scaled_X_val, y_val)).batch(32).prefetch(1)"""

steps_per_epoch_vvg16 = int(len(scaled_X_train) / 32)
validation_steps_vgg16 = int(len(scaled_X_val) / 32)

input_shape = (160, 160, 3)
base_model = VGG16(weights="imagenet", include_top=False, input_shape=input_shape)
base_model.summary()

vgg16_model = Sequential([base_model,
                          Flatten(),
                          Dropout(0.3),
                          Dense(512, activation="relu", kernel_initializer="he_normal"),
                          Dense(1, activation="sigmoid")],
                         name="vgg16_model")

base_model.trainable = False
set_trainable = False
""" ev testa om ovan inte funkar
for layer in base_model.layers:
    layer.trainable = False
"""
"""for layer in vgg16_model.layers:
    if layer.name == 'block5_conv1':
        set_trainable = True
    if set_trainable:
        layer.trainable = True
    else:
        layer.trainable = False"""

vgg16_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['acc'])  # 1e-5 RMSprop(lr=0.001)
# vgg16_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["acc"]) gamla innan set trainable
vgg16_model.summary()

early_stopper = EarlyStopping(monitor="val_acc", mode="max", patience=5, restore_best_weights=True)
vgg16_model.fit(wo_augumented_train_generator,
                steps_per_epoch=steps_per_epoch_vvg16,
                epochs=5,
                callbacks=early_stopper,
                validation_data=val_generator,
                validation_steps=validation_steps_vgg16)

metrics = pd.DataFrame(vgg16_model.history.history)
plot_metrics(metrics, "vgg16")
evaluation(vgg16_model, scaled_X_val, y_val, "vgg16_wo_Augmented_Tuning_train__val")  # ska vara val inte test

"""
base_model2 = Xception(weights="imagenet", include_top=False, input_shape=input_shape)
base_model2.summary()

xception_model = Sequential([base_model2,
                             GlobalAveragePooling2D(),
                             Dropout(0.5),
                             Dense(512, activation="relu", kernel_initializer="he_normal"),
                             Dense(1, activation="sigmoid")],
                             name="xception_model")  # dense(256 - 256 labels!!! GlobalAveragePooling2D()

# fryser layers vikter och ev bias
for layer in xception_model.layers:
    layer.trainable = False

xception_model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["acc"])
xception_model.summary()

# xception_model.fit(train_dataset, epochs=100, validation_data=test_dataset)
early_stopper = EarlyStopping(monitor="val_acc", mode="max", patience=15, restore_best_weights=True)
xception_model.fit(train_val_generator, epochs=30, validation_data=test_generator, callbacks=early_stopper)
metrics2 = pd.DataFrame(xception_model.history.history)
plot_metrics(metrics2, "xception")
evaluation(model, scaled_X_test, y_test, "xception")
"""
